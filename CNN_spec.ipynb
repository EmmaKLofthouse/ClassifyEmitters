{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a CNN to classify trimmed spectra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in individual datacubes and combine into a single dataframe\n",
    "\n",
    "from astropy.table import Table\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "sightline_list = ['J010619+004823','J012403+004432','J013340+040059','J013724-422417','J015741-010629']#,\n",
    "                  #'J020944+051713','J024401-013403']#,'J033413-161205','J033900-013318','J094932+033531',\n",
    "                  #'J095852+120245']#,'J102009+104002','J111008+024458','J111113-080401','J120917+113830',\n",
    "                  #'J123055-113909','J124957-015928','J133254+005250','J142438+225600','J162116-004251',\n",
    "                  #'J193957-100241','J200324-325145','J205344-354652','J221527-161133','J230301-093930',\n",
    "                  #'J231543+145606','J233446-090812','J234913-371259']\n",
    "\n",
    "\n",
    "for sightline in sightline_list:\n",
    "    table = Table.read('/home/emma/Documents/laeML/data/catalogues/individual_cubes/{}_cubex_data.fits'.format(sightline))\n",
    "    table['sightline'] = sightline\n",
    "    pandas_df = table.to_pandas()\n",
    "    df = pd.concat([df,pandas_df])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut to SNR > 7 as we haven't looked at all the sources below this\n",
    "df = df[df.SNR >= 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n"
     ]
    }
   ],
   "source": [
    "# Check number of LAEs\n",
    "type_str = df['type'].str.decode(\"utf-8\")\n",
    "nLAE = type_str.str.contains('LAE').sum()\n",
    "print(nLAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column to show if entry is an LAE\n",
    "df['isLAE'] = np.where(type_str.str.contains('LAE'), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use 1D flux arrays from the trimmed spectra as input to our CNN (i.e. X) while is_LAE is the target (i.e. Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.isLAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to read in the flux columns from the trimmed arrays and combine into a dataframe to use as X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#create empty list\\nxlist = []\\n\\nfrom astropy.io import fits\\n\\n#loop over entries, find the trimmed spectrum, add to dataframe\\nfor row in df.itertuples(index=True, name='Pandas'):\\n    trimmed_file = '/home/emma/Documents/laeML/data/trimmed_spec/{}/spec_trim_id{}_-100A_+100A.fits'.format(row.sightline,row.id)\\n    \\n    #read in spectrum\\n    try:\\n        with fits.open(trimmed_file) as spec:\\n            flx = spec[0].data\\n            xlist.append(flx)\\n    except:\\n        print('Couldn't find: ' +str(row.sightline) + ' id' + str(row.id))\\n        continue\\n        \\n    \\n#convert list to dataframe. This is quicker than growing a dataframe row-wise\\nx = pd.DataFrame(xlist)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#create empty list\n",
    "xlist = []\n",
    "\n",
    "from astropy.io import fits\n",
    "\n",
    "#loop over entries, find the trimmed spectrum, add to dataframe\n",
    "for row in df.itertuples(index=True, name='Pandas'):\n",
    "    trimmed_file = '/home/emma/Documents/laeML/data/trimmed_spec/{}/spec_trim_id{}_-100A_+100A.fits'.format(row.sightline,row.id)\n",
    "    \n",
    "    #read in spectrum\n",
    "    try:\n",
    "        with fits.open(trimmed_file) as spec:\n",
    "            flx = spec[0].data\n",
    "            xlist.append(flx)\n",
    "    except:\n",
    "        print('Couldn\\'t find: ' +str(row.sightline) + ' id' + str(row.id))\n",
    "        continue\n",
    "        \n",
    "    \n",
    "#convert list to dataframe. This is quicker than growing a dataframe row-wise\n",
    "x = pd.DataFrame(xlist)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of creating x from each file individually, read it in from a prepared file\n",
    "x=pd.read_csv(\"/home/emma/Documents/laeML/data/trimmed_spectra_dataframe.csv\",index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>590.384766</td>\n",
       "      <td>454.941467</td>\n",
       "      <td>354.345154</td>\n",
       "      <td>328.243042</td>\n",
       "      <td>5.348419</td>\n",
       "      <td>70.211662</td>\n",
       "      <td>235.562622</td>\n",
       "      <td>207.469299</td>\n",
       "      <td>137.152069</td>\n",
       "      <td>109.381187</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>452.941223</td>\n",
       "      <td>427.720490</td>\n",
       "      <td>435.023926</td>\n",
       "      <td>538.362366</td>\n",
       "      <td>448.548431</td>\n",
       "      <td>518.894287</td>\n",
       "      <td>402.824951</td>\n",
       "      <td>319.419006</td>\n",
       "      <td>319.533020</td>\n",
       "      <td>267.410187</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237.862305</td>\n",
       "      <td>131.504059</td>\n",
       "      <td>196.990021</td>\n",
       "      <td>375.919373</td>\n",
       "      <td>264.392822</td>\n",
       "      <td>225.224884</td>\n",
       "      <td>189.368408</td>\n",
       "      <td>158.257416</td>\n",
       "      <td>97.674271</td>\n",
       "      <td>99.918762</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>371.443054</td>\n",
       "      <td>337.741241</td>\n",
       "      <td>242.179245</td>\n",
       "      <td>256.283417</td>\n",
       "      <td>389.117188</td>\n",
       "      <td>477.863403</td>\n",
       "      <td>372.696228</td>\n",
       "      <td>448.540527</td>\n",
       "      <td>375.683411</td>\n",
       "      <td>559.601074</td>\n",
       "      <td>...</td>\n",
       "      <td>290.749451</td>\n",
       "      <td>296.189941</td>\n",
       "      <td>207.545380</td>\n",
       "      <td>299.615936</td>\n",
       "      <td>240.926071</td>\n",
       "      <td>307.433838</td>\n",
       "      <td>527.028931</td>\n",
       "      <td>481.803894</td>\n",
       "      <td>500.537750</td>\n",
       "      <td>474.636536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.715321</td>\n",
       "      <td>-27.427366</td>\n",
       "      <td>42.573402</td>\n",
       "      <td>34.838043</td>\n",
       "      <td>89.349220</td>\n",
       "      <td>-45.284454</td>\n",
       "      <td>-17.226364</td>\n",
       "      <td>-45.073406</td>\n",
       "      <td>23.561562</td>\n",
       "      <td>-54.283142</td>\n",
       "      <td>...</td>\n",
       "      <td>114.334274</td>\n",
       "      <td>35.456001</td>\n",
       "      <td>-106.346481</td>\n",
       "      <td>25.491888</td>\n",
       "      <td>45.191193</td>\n",
       "      <td>45.270767</td>\n",
       "      <td>-9.925606</td>\n",
       "      <td>-58.586670</td>\n",
       "      <td>39.541794</td>\n",
       "      <td>29.653870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3           4           5  \\\n",
       "0  590.384766  454.941467  354.345154  328.243042    5.348419   70.211662   \n",
       "1  452.941223  427.720490  435.023926  538.362366  448.548431  518.894287   \n",
       "2  237.862305  131.504059  196.990021  375.919373  264.392822  225.224884   \n",
       "3  371.443054  337.741241  242.179245  256.283417  389.117188  477.863403   \n",
       "4   47.715321  -27.427366   42.573402   34.838043   89.349220  -45.284454   \n",
       "\n",
       "            6           7           8           9  ...         150  \\\n",
       "0  235.562622  207.469299  137.152069  109.381187  ...         NaN   \n",
       "1  402.824951  319.419006  319.533020  267.410187  ...         NaN   \n",
       "2  189.368408  158.257416   97.674271   99.918762  ...         NaN   \n",
       "3  372.696228  448.540527  375.683411  559.601074  ...  290.749451   \n",
       "4  -17.226364  -45.073406   23.561562  -54.283142  ...  114.334274   \n",
       "\n",
       "          151         152         153         154         155         156  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3  296.189941  207.545380  299.615936  240.926071  307.433838  527.028931   \n",
       "4   35.456001 -106.346481   25.491888   45.191193   45.270767   -9.925606   \n",
       "\n",
       "          157         158         159  \n",
       "0         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN  \n",
       "2         NaN         NaN         NaN  \n",
       "3  481.803894  500.537750  474.636536  \n",
       "4  -58.586670   39.541794   29.653870  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3846, 160, 1)\n"
     ]
    }
   ],
   "source": [
    "x = np.array(x).reshape(x.shape[0], x.shape[1], 1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n"
     ]
    }
   ],
   "source": [
    "nLAE_trainSample = len(y_train[y_train==1])\n",
    "print(nLAE_trainSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create simple test data\n",
    "#import random\n",
    "#xfake = np.empty(x.shape)\n",
    "#yfake=np.empty(y.shape)\n",
    "#for i in range(len(xfake_test)):\n",
    "#    k=random.randint(0, 1)\n",
    "#    xfake[i] = k\n",
    "#    yfake[i] = k\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xfake_train, xfake_test, yfake_train, yfake_test=train_test_split(xfake, yfake, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create simple CNN\n",
    "\n",
    "#import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 2, activation=\"relu\", input_shape=(160,1)))\n",
    "model.add(Dense(16, activation=\"relu\", input_shape=(160,1)))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 159, 64)           192       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 159, 16)           1040      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 79, 16)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1264)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1265      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,497\n",
      "Trainable params: 2,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', \n",
    "     optimizer = \"adam\",               \n",
    "    metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 1.0975 - accuracy: 0.9324 - val_loss: 0.3476 - val_accuracy: 0.9515\n",
      "Epoch 2/30\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.3838 - accuracy: 0.9367 - val_loss: 0.1849 - val_accuracy: 0.9463\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2144 - accuracy: 0.9428 - val_loss: 0.1518 - val_accuracy: 0.9463\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.1477 - accuracy: 0.9495 - val_loss: 0.1400 - val_accuracy: 0.9376\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.1257 - accuracy: 0.9538 - val_loss: 0.1474 - val_accuracy: 0.9376\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.1146 - accuracy: 0.9523 - val_loss: 0.1296 - val_accuracy: 0.9480\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.1085 - accuracy: 0.9544 - val_loss: 0.1293 - val_accuracy: 0.9549\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.1027 - accuracy: 0.9572 - val_loss: 0.1242 - val_accuracy: 0.9497\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0993 - accuracy: 0.9593 - val_loss: 0.1233 - val_accuracy: 0.9515\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0965 - accuracy: 0.9581 - val_loss: 0.1258 - val_accuracy: 0.9515\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0927 - accuracy: 0.9602 - val_loss: 0.1236 - val_accuracy: 0.9549\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0888 - accuracy: 0.9630 - val_loss: 0.1231 - val_accuracy: 0.9532\n",
      "Epoch 13/30\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0856 - accuracy: 0.9636 - val_loss: 0.1230 - val_accuracy: 0.9515\n",
      "Epoch 14/30\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0823 - accuracy: 0.9627 - val_loss: 0.1266 - val_accuracy: 0.9497\n",
      "Epoch 15/30\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0789 - accuracy: 0.9657 - val_loss: 0.1387 - val_accuracy: 0.9463\n",
      "Epoch 16/30\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0784 - accuracy: 0.9676 - val_loss: 0.1396 - val_accuracy: 0.9445\n",
      "Epoch 17/30\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0743 - accuracy: 0.9700 - val_loss: 0.1330 - val_accuracy: 0.9497\n",
      "Epoch 18/30\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0728 - accuracy: 0.9697 - val_loss: 0.1353 - val_accuracy: 0.9463\n",
      "Epoch 19/30\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0725 - accuracy: 0.9688 - val_loss: 0.1364 - val_accuracy: 0.9480\n",
      "Epoch 20/30\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.1067 - accuracy: 0.9657 - val_loss: 0.1823 - val_accuracy: 0.9341\n",
      "Epoch 21/30\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.1199 - accuracy: 0.9581 - val_loss: 0.1460 - val_accuracy: 0.9393\n",
      "Epoch 22/30\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0837 - accuracy: 0.9639 - val_loss: 0.1442 - val_accuracy: 0.9463\n",
      "Epoch 23/30\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0742 - accuracy: 0.9685 - val_loss: 0.1488 - val_accuracy: 0.9532\n",
      "Epoch 24/30\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0696 - accuracy: 0.9691 - val_loss: 0.1543 - val_accuracy: 0.9497\n",
      "Epoch 25/30\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0683 - accuracy: 0.9706 - val_loss: 0.1583 - val_accuracy: 0.9480\n",
      "Epoch 26/30\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0644 - accuracy: 0.9697 - val_loss: 0.1725 - val_accuracy: 0.9341\n",
      "Epoch 27/30\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0626 - accuracy: 0.9746 - val_loss: 0.1692 - val_accuracy: 0.9393\n",
      "Epoch 28/30\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0624 - accuracy: 0.9734 - val_loss: 0.1760 - val_accuracy: 0.9393\n",
      "Epoch 29/30\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0577 - accuracy: 0.9758 - val_loss: 0.1725 - val_accuracy: 0.9428\n",
      "Epoch 30/30\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0550 - accuracy: 0.9768 - val_loss: 0.1850 - val_accuracy: 0.9376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f20cb9780d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=100,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.185048446059227\n",
      "Test accuracy: 0.9376083016395569\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!! SHOULD DO TEST ON SEPARATE DATA NOT THE STUFF USED FOR VALIDATION !!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = model.predict(x_test)\n",
    "ypred = np.array(ypred)\n",
    "\n",
    "for yi in range(len(ypred)):\n",
    "    if ypred[yi]<0.5:\n",
    "        ypred[yi] = 0\n",
    "    else:\n",
    "        ypred[yi] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "y_test=np.array(y_test)\n",
    "nLAE_testsample = len(y_test[y_test==1])\n",
    "print(nLAE_testsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "isLAE_and_predLAE,isLAE_and_NotpredLAE,NotLAE_and_predLAE, NotLAE_and_NotpredLAE = 0,0,0,0\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if (y_test[i] == 1) & (ypred[i][0]==1):\n",
    "        isLAE_and_predLAE += 1 # Number of True LAEs predicted to be LAEs\n",
    "    elif (y_test[i] == 1) & (ypred[i][0]!=1):\n",
    "        isLAE_and_NotpredLAE += 1 # Number of True LAEs bot predicted to be LAEs\n",
    "    if (y_test[i] != 1) & (ypred[i][0]==1):\n",
    "        NotLAE_and_predLAE += 1 # Number of not LAEs predicted to be LAEs\n",
    "    if (y_test[i] != 1) & (ypred[i][0] != 1):\n",
    "        NotLAE_and_NotpredLAE += 1 # Number of not LAEs predicted to not be LAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 16 20 531\n"
     ]
    }
   ],
   "source": [
    "print(isLAE_and_predLAE,isLAE_and_NotpredLAE,NotLAE_and_predLAE,NotLAE_and_NotpredLAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
